{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_tags</th>\n",
       "      <th>original_tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182914</th>\n",
       "      <td>tensorflow,keras</td>\n",
       "      <td>tensorflow,keras,deep-learning,lstm,word-embed...</td>\n",
       "      <td>avocado image captioning model not compiling b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48361</th>\n",
       "      <td>pandas</td>\n",
       "      <td>python,pandas,flask</td>\n",
       "      <td>return excel file from avocado with flask in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181447</th>\n",
       "      <td>tensorflow,keras</td>\n",
       "      <td>python,validation,tensorflow,keras,data-genera...</td>\n",
       "      <td>validating with generator (avocado) i'm trying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66307</th>\n",
       "      <td>pandas</td>\n",
       "      <td>python,pandas,dataframe</td>\n",
       "      <td>avocado multiindex dataframe selecting data gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11283</th>\n",
       "      <td>pandas</td>\n",
       "      <td>python,python-3.x,pandas</td>\n",
       "      <td>get rightmost non-zero value position for each...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          extracted_tags                                      original_tags  \\\n",
       "182914  tensorflow,keras  tensorflow,keras,deep-learning,lstm,word-embed...   \n",
       "48361             pandas                                python,pandas,flask   \n",
       "181447  tensorflow,keras  python,validation,tensorflow,keras,data-genera...   \n",
       "66307             pandas                            python,pandas,dataframe   \n",
       "11283             pandas                           python,python-3.x,pandas   \n",
       "\n",
       "                                                     text  \n",
       "182914  avocado image captioning model not compiling b...  \n",
       "48361   return excel file from avocado with flask in f...  \n",
       "181447  validating with generator (avocado) i'm trying...  \n",
       "66307   avocado multiindex dataframe selecting data gi...  \n",
       "11283   get rightmost non-zero value position for each...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_CSV_FILENAME = \"text_tags_188k.csv\"\n",
    "\n",
    "data = pd.read_csv(DATASET_CSV_FILENAME)\n",
    "data = shuffle(data, random_state=22)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_split = [tags.split(\",\") for tags in data[\"extracted_tags\"].values]\n",
    "\n",
    "tag_encoder = MultiLabelBinarizer()\n",
    "tags_encoded = tag_encoder.fit_transform(tags_split)\n",
    "num_tags = len(tags_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 150559\n",
      "Test size: 37640\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * .8)\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Test size: {len(data) - train_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags = tags_encoded[:train_size]\n",
    "test_tags = tags_encoded[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text\n",
    "\n",
    "class TextPreprocessor(object):\n",
    "    def __init__(self, vocab_size):\n",
    "        self._vocab_size = vocab_size\n",
    "        self._tokenizer = None\n",
    "    \n",
    "    def create_tokenizer(self, text_list):\n",
    "        tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
    "        tokenizer.fit_on_texts(text_list)\n",
    "        self._tokenizer = tokenizer\n",
    "\n",
    "    def transform_text(self, text_list):\n",
    "        text_matrix = self._tokenizer.texts_to_matrix(text_list)\n",
    "        return text_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qs = data[\"text\"].values[:train_size]\n",
    "test_qs = data[\"text\"].values[train_size:]\n",
    "\n",
    "VOCAB_SIZE = 400\n",
    "\n",
    "processor = TextPreprocessor(VOCAB_SIZE)\n",
    "processor.create_tokenizer(train_qs)\n",
    "\n",
    "body_train = processor.transform_text(train_qs)\n",
    "body_test = processor.transform_text(test_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(len(body_train[0]))\n",
    "print(body_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./processor_state.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_29 (Dense)            (None, 50)                20050     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 5)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,455\n",
      "Trainable params: 21,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(vocab_size, num_tags):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_shape=(vocab_size,), activation=\"relu\"))\n",
    "    model.add(Dense(25, activation=\"relu\"))\n",
    "    model.add(Dense(num_tags, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = create_model(vocab_size=VOCAB_SIZE, num_tags=num_tags)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0969 - accuracy: 0.8993 - val_loss: 0.0989 - val_accuracy: 0.8978\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0938 - accuracy: 0.9016 - val_loss: 0.0964 - val_accuracy: 0.8982\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0910 - accuracy: 0.9046 - val_loss: 0.0966 - val_accuracy: 0.8987\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0885 - accuracy: 0.9071 - val_loss: 0.0958 - val_accuracy: 0.9010\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0862 - accuracy: 0.9092 - val_loss: 0.0963 - val_accuracy: 0.9010\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0842 - accuracy: 0.9118 - val_loss: 0.0971 - val_accuracy: 0.9020\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0824 - accuracy: 0.9140 - val_loss: 0.0975 - val_accuracy: 0.8980\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0809 - accuracy: 0.9152 - val_loss: 0.0989 - val_accuracy: 0.8997\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0795 - accuracy: 0.9169 - val_loss: 0.1009 - val_accuracy: 0.8980\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0782 - accuracy: 0.9178 - val_loss: 0.1007 - val_accuracy: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x287b419d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(body_train, train_tags, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 2s 5ms/step - loss: 0.1039 - accuracy: 0.8950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10386884957551956, 0.8950318694114685]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(body_test, test_tags, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras_saved_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class CustomModelPrediction(object):\n",
    "    def __init__(self, model, processor):\n",
    "        self._model = model\n",
    "        self._processor = processor\n",
    "\n",
    "    def predict(self, instances, **kwargs):\n",
    "        preprocessed_data = self._processor.transform_text(instances)\n",
    "        predictions = self._model.predict(preprocessed_data)\n",
    "        return predictions.tolist()\n",
    "\n",
    "    @classmethod\n",
    "    def from_path(cls, model_dir):\n",
    "        import tensorflow.keras as keras\n",
    "        model = keras.models.load_model(os.path.join(model_dir, \"keras_saved_model.h5\"))\n",
    "        with open(os.path.join(model_dir, \"processor_state.pkl\"), \"rb\") as f:\n",
    "            processor = pickle.load(f)\n",
    "\n",
    "        return cls(model, processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_requests = [\n",
    "    \"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error:\",\n",
    "    \"Change the bar item name in Pandas I have a test excel file like:\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3606712818145752, 6.416594987967983e-05, 0.004043933469802141, 0.0017825100803747773, 0.8948200941085815], [0.011447940021753311, 0.041343145072460175, 0.7622106671333313, 0.03102044016122818, 0.08442071825265884]]\n",
      "Predicted labels:\n",
      "tensorflow\n",
      "\n",
      "\n",
      "Predicted labels:\n",
      "pandas\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 02:10:26.990840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "classifier = CustomModelPrediction.from_path(\".\")\n",
    "results = classifier.predict(test_requests)\n",
    "print(results)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    print(\"Predicted labels:\")\n",
    "    for idx, val in enumerate(results[i]):\n",
    "        if val > 0.7:\n",
    "            print(tag_encoder.classes_[idx])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7a0a9d7ba9d0048b290b174152979f594ac9035e5cf6b8f0b5c496811b14dbb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('env_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
